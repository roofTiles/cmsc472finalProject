{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoQaT5Sk5qOf"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfSsM2Xl492v"
      },
      "source": [
        "This notebook will be for environment setup and for producing the baseline result using ResNet-50. Run the **Prerequisities** section once to get the VizWiz dataset. Under **Prerequisities** there will be two sections for installing the *timm* library (contains pre-trained models). One section will be dedicated just for a local installation if you are running this on your laptop and another for a Google CoLab installation so we don't have to keep on installing the library everytime."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ],
      "metadata": {
        "id": "4cD7dPzfwDtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show button and code\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD7nnjjiwF2T",
        "outputId": "9ee90687-4a7f-4223-ea7f-d1be47006742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvHsfrO5x_zC"
      },
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k28aHolGxWo6"
      },
      "source": [
        "#### Download the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFx7yFf23Ru4"
      },
      "source": [
        "In this stage, we want to download all images available in VizWiz dataset. Downloading images and annotations may take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_DmRRx2vWT7",
        "outputId": "89178817-2f56-4080-c3d8-ba3729c1c5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-14 15:18:42--  https://vizwiz.cs.colorado.edu/VizWiz_final/images/train.zip\n",
            "Resolving vizwiz.cs.colorado.edu (vizwiz.cs.colorado.edu)... 198.59.7.50\n",
            "Connecting to vizwiz.cs.colorado.edu (vizwiz.cs.colorado.edu)|198.59.7.50|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11298421598 (11G) [application/zip]\n",
            "Saving to: ‘train.zip’\n",
            "\n",
            "train.zip           100%[===================>]  10.52G  15.4MB/s    in 12m 2s  \n",
            "\n",
            "2024-04-14 15:30:45 (14.9 MB/s) - ‘train.zip’ saved [11298421598/11298421598]\n",
            "\n",
            "--2024-04-14 15:30:45--  https://vizwiz.cs.colorado.edu/VizWiz_final/images/val.zip\n",
            "Reusing existing connection to vizwiz.cs.colorado.edu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3488913457 (3.2G) [application/zip]\n",
            "Saving to: ‘val.zip’\n",
            "\n",
            "val.zip             100%[===================>]   3.25G  14.9MB/s    in 3m 49s  \n",
            "\n",
            "2024-04-14 15:34:35 (14.5 MB/s) - ‘val.zip’ saved [3488913457/3488913457]\n",
            "\n",
            "--2024-04-14 15:34:35--  https://vizwiz.cs.colorado.edu/VizWiz_final/images/test.zip\n",
            "Reusing existing connection to vizwiz.cs.colorado.edu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3975272799 (3.7G) [application/zip]\n",
            "Saving to: ‘test.zip’\n",
            "\n",
            "test.zip            100%[===================>]   3.70G  15.8MB/s    in 4m 30s  \n",
            "\n",
            "2024-04-14 15:39:05 (14.0 MB/s) - ‘test.zip’ saved [3975272799/3975272799]\n",
            "\n",
            "FINISHED --2024-04-14 15:39:06--\n",
            "Total wall clock time: 20m 24s\n",
            "Downloaded: 3 files, 17G in 20m 22s (14.6 MB/s)\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p dataset/images predictions\n",
        "!wget https://vizwiz.cs.colorado.edu/VizWiz_final/images/train.zip \\\n",
        "      https://vizwiz.cs.colorado.edu/VizWiz_final/images/val.zip \\\n",
        "      https://vizwiz.cs.colorado.edu/VizWiz_final/images/test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nd8TgGrq2MBa"
      },
      "outputs": [],
      "source": [
        "!unzip -q -o train.zip -d dataset/images\n",
        "!unzip -q -o val.zip -d dataset/images\n",
        "!unzip -q -o test.zip -d dataset/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXzJ0gjM4H2J"
      },
      "outputs": [],
      "source": [
        "!rm train.zip val.zip test.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyjPLJKlxaew"
      },
      "source": [
        "#### Install timm (local)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCgwLoH7vTR6",
        "outputId": "f2a514b9-2511-455e-f03f-58e9127d3ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.0+cu116)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.0+cu116)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.9.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.11.1 timm-0.6.12\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install timm (colab)"
      ],
      "metadata": {
        "id": "ITK48kbuvQne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install virtualenv\n",
        "!virtualenv \"/content/drive/MyDrive/CMSC_472/CMSC 472 Project/Code/virtual_env\"\n",
        "!chmod 755 \"/content/drive/MyDrive/CMSC_472/CMSC 472 Project/Code/virtual_env/bin/activate\"; pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4n1Z9CVvUT8",
        "outputId": "7007bbbb-e387-41fd-b0bf-6ea9a3c81b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.26.1-py3-none-any.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.13.4)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.2.1)\n",
            "Installing collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.3.8 virtualenv-20.26.1\n",
            "created virtual environment CPython3.10.12.final.0-64 in 22843ms\n",
            "  creator CPython3Posix(dest=/content/drive/MyDrive/CMSC_472/CMSC 472 Project/Code/virtual_env, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==24.0, setuptools==69.5.1, wheel==0.43.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->timm)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 timm-0.9.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVWg6brFyK1i"
      },
      "source": [
        "### Get predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdWGQB2ZxP4o"
      },
      "source": [
        "#### Import libraries (local)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK4HAU7jvIkV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import timm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Libraries (CoLab)"
      ],
      "metadata": {
        "id": "PDr0H8sQvpMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# changes working directory to cmsc_472 shared proj file\n",
        "os.chdir(\"/content/drive/MyDrive/CMSC_472/CMSC 472 Project/Code/\")\n",
        "\n",
        "import sys\n",
        "# add the path of the virtual environmentsite-packages to colab system path\n",
        "sys.path.append(\"virtual_env/lib/python3.10/site-packages\")\n",
        "import timm"
      ],
      "metadata": {
        "id": "Q_nybOUyv5nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySt0VVvqwbj9"
      },
      "source": [
        "#### Set variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iomVcQhvJ3E"
      },
      "outputs": [],
      "source": [
        "ann_path = 'dataset/annotations.json'\n",
        "images_path = 'dataset/images'\n",
        "prediction_path = 'predictions/'\n",
        "\n",
        "# change model name based on what you are training\n",
        "#model_name = 'resnet50'\n",
        "model_name = 'vit_base_patch32_224'\n",
        "\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAl97lEMwjNA"
      },
      "source": [
        "#### Load annotation file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Eow13OHwKVm"
      },
      "outputs": [],
      "source": [
        "annotations = json.load(open(ann_path))\n",
        "indices_in_1k = [d['id'] for d in annotations['categories']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cFQeOsuwnjI"
      },
      "source": [
        "#### Set device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFS6FYp0wrmx"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tg8jyuAwxKw"
      },
      "source": [
        "#### Create dataset class and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "137pPGf9wzfL"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    # for normalization use top for\n",
        "    # ViT and bottom for ResNet\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                          std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "    #                      std=[0.229, 0.224, 0.225])\n",
        "    #])\n",
        "\n",
        "class VizWizClassification(Dataset):\n",
        "    def __init__(self, annotations, transform=None):\n",
        "        self.images = []\n",
        "        for img in annotations['images']:\n",
        "          if 'train' in img:\n",
        "            self.images.append(images_path + '/train/' + str(img))\n",
        "\n",
        "          if 'val' in img:\n",
        "            self.images.append(images_path + '/val/' + str(img))\n",
        "\n",
        "          if 'test' in img:\n",
        "            self.images.append(images_path + '/test/' + str(img))\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.images[idx]).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.images[idx].split(\"/\")[3]\n",
        "\n",
        "dataset = VizWizClassification(annotations,test_transform)\n",
        "vizwiz_loader = torch.utils.data.DataLoader(dataset,batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWeIH-miw2vA"
      },
      "source": [
        "#### Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmJ9MZS-w9K-",
        "outputId": "86ac8fea-fbd8-4ec3-d193-cee0235cbede"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
              "    (norm): Identity()\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (patch_drop): Identity()\n",
              "  (norm_pre): Identity()\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (2): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (3): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (4): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (5): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (6): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (7): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (8): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (9): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (10): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (11): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (fc_norm): Identity()\n",
              "  (head_drop): Dropout(p=0.0, inplace=False)\n",
              "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model = timm.create_model(model_name, pretrained=True).to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHhEcb0QxGl2"
      },
      "source": [
        "#### Get predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqUdCiEXy9jX"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "with torch.no_grad():\n",
        "    for images, images_path in vizwiz_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)[:,indices_in_1k]\n",
        "        pred = list(outputs.data.max(1)[1].cpu())\n",
        "        for i in range(len(pred)):\n",
        "                results[images_path[i]] = indices_in_1k[pred[i]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6KngDktzAf5"
      },
      "source": [
        "### Save the prediction file for EvalAI server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCcttfFfy_fT"
      },
      "outputs": [],
      "source": [
        "file_path = os.path.join(prediction_path, datetime.now().strftime(\"prediction-%m-%d-%Y-%H:%M:%S.json\"))\n",
        "with open(file_path, 'w') as outfile:\n",
        "    json.dump(results, outfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLjHu5VP_eoW"
      },
      "source": [
        "Now you can upload this file on EvalAI server."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fyjPLJKlxaew",
        "ITK48kbuvQne",
        "sdWGQB2ZxP4o"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}